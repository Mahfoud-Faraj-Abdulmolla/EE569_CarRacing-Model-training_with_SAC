# CarRacing-v3: SAC Implementation

## Overview
This repository contains an implementation of **Soft Actor-Critic (SAC)** for the CarRacing-v3 environment. The agent learns to drive from raw pixel inputs (84Ã—84 grayscale images) using deep reinforcement learning.

## Features
- **Algorithm:** Soft Actor-Critic (SAC)
- **Input:** 84Ã—84 grayscale pixels (4-frame stack)
- **Output:** Continuous actions (steering, acceleration, brake)
- **Evaluation:** 3 episodes as per assignment requirements
- **Performance:** >700 average reward achieved

## Installation
```bash
pip install -r requirements.txt
Usage
Training
bash
python train.py
Evaluation & Video Recording
bash
python inference.py --checkpoint checkpoints/best_actor.pth --episodes 3 --save-video
Project Structure
text
â”œâ”€â”€ train.py                 # Training script
â”œâ”€â”€ inference.py             # Evaluation script
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ checkpoints/            # Saved models
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â””â”€â”€ best_actor.pth
â”œâ”€â”€ videos/                 # Recorded runs
â”‚   â””â”€â”€ best_run.mp4
â”œâ”€â”€ logs/                   # TensorBoard logs
â””â”€â”€ README.md
Model Architecture
CNN Encoder: 3 convolutional layers (96â†’192â†’256)

Actor Network: Gaussian policy with automatic entropy tuning

Critic Networks: Twin Q-networks (TD3-style)

Hidden Layers: 1536 units with residual connections

Hyperparameters
Parameter	Value
Learning Rate	8e-5
Batch Size	768
Discount Factor (Î³)	0.99
Target Update (Ï„)	0.005
Replay Buffer Size	3M
Initial Exploration Steps	5000
Results
âœ… Assignment Requirement Met: >700 average reward over 3 episodes

ðŸ“ˆ Training Logs: Available via TensorBoard

ðŸŽ¥ Best Run Video: videos/best_run.mp4

Requirements Checklist
Pixel input (84Ã—84)

Average reward > 700

3-episode evaluation

Video recording capability

TensorBoard logging

Clean, modular code
